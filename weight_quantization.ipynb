{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'demo.nets.nmnist.LeNetNetwork'>\n",
      "LeNetNetwork(\n",
      "  (slayer): spikeLayer()\n",
      "  (SC1): _convLayer(2, 6, kernel_size=(7, 7, 1), stride=(1, 1, 1), bias=False)\n",
      "  (SC2): _convLayer(6, 16, kernel_size=(5, 5, 1), stride=(1, 1, 1), bias=False)\n",
      "  (SC3): _convLayer(16, 120, kernel_size=(5, 5, 1), stride=(1, 1, 1), bias=False)\n",
      "  (SP1): _poolLayer(1, 1, kernel_size=(2, 2, 1), stride=(2, 2, 1), bias=False)\n",
      "  (SP2): _poolLayer(1, 1, kernel_size=(2, 2, 1), stride=(2, 2, 1), bias=False)\n",
      "  (SF1): _denseLayer(120, 84, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  (SF2): _denseLayer(84, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "  (SDC): _dropoutLayer(p=0.4, inplace=False)\n",
      "  (SDF): _dropoutLayer(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the .pkl file\n",
    "file_path = \"/shares/bulk/vgandham/SpikeFI/out/net/nmnist-lenet/nmnist-lenet_net2.pt\"  # Replace with your actual file path\n",
    "model_data = torch.load(file_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Check the type of the loaded object\n",
    "print(type(model_data))\n",
    "print(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available layers in the model:\n",
      "odict_keys(['slayer.srmKernel', 'slayer.refKernel', 'SC1.weight', 'SC2.weight', 'SC3.weight', 'SP1.weight', 'SP2.weight', 'SF1.weight', 'SF2.weight'])\n"
     ]
    }
   ],
   "source": [
    "# Extract the state dictionary (weights)\n",
    "state_dict = model_data.state_dict()\n",
    "\n",
    "# Print all available layers\n",
    "print(\"Available layers in the model:\")\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC1.weight torch.Size([6, 2, 7, 7, 1])\n",
      "SC2.weight torch.Size([16, 6, 5, 5, 1])\n",
      "SC3.weight torch.Size([120, 16, 5, 5, 1])\n",
      "SP1.weight torch.Size([1, 1, 2, 2, 1])\n",
      "SP2.weight torch.Size([1, 1, 2, 2, 1])\n",
      "SF1.weight torch.Size([84, 120, 1, 1, 1])\n",
      "SF2.weight torch.Size([10, 84, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_data.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srmKernel shape: torch.Size([77])\n",
      "refKernel shape: torch.Size([11])\n"
     ]
    }
   ],
   "source": [
    "print(\"srmKernel shape:\", state_dict[\"slayer.srmKernel\"].shape)\n",
    "print(\"refKernel shape:\", state_dict[\"slayer.refKernel\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slayer.srmKernel: min=0.0, max=1.0\n",
      "slayer.refKernel: min=-20.0, max=-0.0\n",
      "SC1.weight: min=-13.337733268737793, max=15.416525840759277\n",
      "SC2.weight: min=-19.57712173461914, max=18.011754989624023\n",
      "SC3.weight: min=-18.200239181518555, max=17.31533432006836\n",
      "SP1.weight: min=11.0, max=11.0\n",
      "SP2.weight: min=11.0, max=11.0\n",
      "SF1.weight: min=-14.966136932373047, max=11.687015533447266\n",
      "SF2.weight: min=-19.792848587036133, max=8.437464714050293\n"
     ]
    }
   ],
   "source": [
    "# Compute min and max values for each parameter\n",
    "layer_ranges = {}\n",
    "\n",
    "for layer_name, weights in state_dict.items():\n",
    "    if isinstance(weights, torch.Tensor):\n",
    "        layer_ranges[layer_name] = {\n",
    "            \"min\": weights.min().item(),\n",
    "            \"max\": weights.max().item()\n",
    "        }\n",
    "\n",
    "# Print results\n",
    "for layer, stats in layer_ranges.items():\n",
    "    print(f\"{layer}: min={stats['min']}, max={stats['max']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slayer.srmKernel: torch.float32\n",
      "slayer.refKernel: torch.float32\n",
      "SC1.weight: torch.float32\n",
      "SC2.weight: torch.float32\n",
      "SC3.weight: torch.float32\n",
      "SP1.weight: torch.float32\n",
      "SP2.weight: torch.float32\n",
      "SF1.weight: torch.float32\n",
      "SF2.weight: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Print the data type of each weight tensor\n",
    "for layer in state_dict.keys():\n",
    "    print(f\"{layer}: {state_dict[layer].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slayer.srmKernel: 77 weights\n",
      "slayer.refKernel: 11 weights\n",
      "SC1.weight: 588 weights\n",
      "SC2.weight: 2400 weights\n",
      "SC3.weight: 48000 weights\n",
      "SP1.weight: 4 weights\n",
      "SP2.weight: 4 weights\n",
      "SF1.weight: 10080 weights\n",
      "SF2.weight: 840 weights\n"
     ]
    }
   ],
   "source": [
    "# Print the number of weights for each layer\n",
    "for layer in state_dict.keys():\n",
    "    num_weights = state_dict[layer].numel()\n",
    "    print(f\"{layer}: {num_weights} weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP1.weight weights:\n",
      "tensor([[[[[11.],\n",
      "           [11.]],\n",
      "\n",
      "          [[11.],\n",
      "           [11.]]]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"SP1.weight weights:\")\n",
    "print(state_dict[\"SP1.weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refKernel weights:\n",
      "tensor([ -0.0000, -20.0000, -14.7152,  -8.1201,  -3.9830,  -1.8316,  -0.8086,\n",
      "         -0.3470,  -0.1459,  -0.0604,  -0.0247])\n"
     ]
    }
   ],
   "source": [
    "print(\"refKernel weights:\")\n",
    "print(state_dict[\"slayer.refKernel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized srmKernel: tensor([-128.,  -65.,  -14.,   26.,   58.,   82.,  100.,  113.,  121.,  126.,\n",
      "         127.,  126.,  123.,  118.,  111.,  104.,   96.,   87.,   78.,   69.,\n",
      "          60.,   50.,   41.,   32.,   23.,   14.,    6.,   -2.,  -10.,  -17.,\n",
      "         -24.,  -31.,  -38.,  -44.,  -49.,  -55.,  -60.,  -65.,  -69.,  -73.,\n",
      "         -77.,  -81.,  -84.,  -88.,  -91.,  -93.,  -96.,  -98., -101., -103.,\n",
      "        -105., -106., -108., -110., -111., -112., -114., -115., -116., -117.,\n",
      "        -118., -119., -119., -120., -121., -121., -122., -122., -123., -123.,\n",
      "        -124., -124., -124., -125., -125., -125., -125.])\n",
      "Quantized weights saved at quantized_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Saving the quantized weights\n",
    "\n",
    "from spikefi.utils import quantization as qua\n",
    "\n",
    "\n",
    "def symmetric_quantize_spikefi(tensor, dtype=torch.qint8):\n",
    "    \"\"\"\n",
    "    Applies symmetric quantization to a tensor while keeping it in float32 format.\n",
    "    Uses the given function `quant_args_from_range` to calculate scale and zero point.\n",
    "    \"\"\"\n",
    "    # Get min and max values of tensor\n",
    "    xmin, xmax = tensor.min(), tensor.max()\n",
    "\n",
    "    # Compute scale and zero point using the provided function\n",
    "    scale, zero_point, dtype = qua.quant_args_from_range(xmin, xmax, dtype)\n",
    "\n",
    "    dt_info = torch.iinfo(dtype)\n",
    "    qmin = dt_info.min\n",
    "    qmax = dt_info.max\n",
    "\n",
    "    # Apply quantization (rounding to nearest discrete level) and keep as float32\n",
    "    quantized_tensor = torch.clamp(((tensor / scale).round() + zero_point),qmin,qmax)\n",
    "\n",
    "    return quantized_tensor # Keep float32 for compatibility\n",
    "\n",
    "\n",
    "quantized_state_dict = {}\n",
    "\n",
    "# Quantize all weights to int8\n",
    "for layer_name, weights in state_dict.items():\n",
    "    \n",
    "    quantized_state_dict[layer_name] = symmetric_quantize_spikefi(weights)\n",
    "\n",
    "# Print example quantized weights\n",
    "print(\"Quantized srmKernel:\", quantized_state_dict[\"slayer.srmKernel\"])\n",
    "\n",
    "# Update the model's weights with the quantized versions\n",
    "model_data.load_state_dict(quantized_state_dict, strict=False)\n",
    "\n",
    "save_path = \"quantized_model.pt\"\n",
    "torch.save(model_data, save_path)\n",
    "print(f\"Quantized weights saved at {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized weights saved at quantized_model_global_scale.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from spikefi.utils import quantization as qua\n",
    "\n",
    "def symmetric_quantize_spikefi(tensor, scale, zero_point):\n",
    "    \"\"\"\n",
    "    Applies symmetric quantization to a tensor while keeping it in float32 format.\n",
    "    \"\"\"\n",
    "    dt_info = torch.iinfo(torch.int8)  # Use INT8 range\n",
    "    qmin, qmax = dt_info.min, dt_info.max\n",
    "\n",
    "    # Apply quantization (rounding to nearest discrete level) but store as float32\n",
    "    quantized_tensor = torch.clamp(((tensor / scale).round() + zero_point), qmin, qmax)\n",
    "\n",
    "    return quantized_tensor  # Keep as float32 for PyTorch compatibility\n",
    "\n",
    "# Step 1: Find Global Min and Max Across All Weights\n",
    "global_min = float(\"inf\")\n",
    "global_max = float(\"-inf\")\n",
    "\n",
    "for layer_name, weights in state_dict.items():\n",
    "    if isinstance(weights, torch.Tensor) and \"slayer\" not in layer_name:  # Exclude neuron parameters\n",
    "        global_min = min(global_min, weights.min().item())\n",
    "        global_max = max(global_max, weights.max().item())\n",
    "\n",
    "# Step 2: Compute a Global Scale and Zero Point\n",
    "global_scale, global_zero_point, _ = qua.quant_args_from_range(global_min, global_max, torch.qint8)\n",
    "\n",
    "# Step 3: Apply Global Quantization to All Weights\n",
    "quantized_state_dict = {}\n",
    "\n",
    "for layer_name, weights in state_dict.items():\n",
    "    if isinstance(weights, torch.Tensor):\n",
    "        quantized_tensor = symmetric_quantize_spikefi(weights, global_scale, global_zero_point)\n",
    "        quantized_state_dict[layer_name] = quantized_tensor\n",
    "    if \"slayer\" in layer_name:\n",
    "        quantized_state_dict[layer_name] = state_dict[layer_name]\n",
    "\n",
    "# Step 4: Ensure Neuron Parameters Use the Same Scale as Weights\n",
    "for neuron_param in [\"slayer.srmKernel\", \"slayer.refKernel\"]:\n",
    "    if neuron_param in state_dict:\n",
    "        quantized_state_dict[neuron_param] = symmetric_quantize_spikefi(state_dict[neuron_param], global_scale, global_zero_point)\n",
    "\n",
    "# Save the quantized model\n",
    "\n",
    "# Update the model's weights with the quantized versions\n",
    "model_data.load_state_dict(quantized_state_dict, strict=False)\n",
    "\n",
    "save_path = \"quantized_model_global_scale.pt\"\n",
    "torch.save(model_data, save_path)\n",
    "print(f\"Quantized weights saved at {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized test: tensor([ 5.,  7.,  8.,  9., 10., 11., 11., 11., 12., 12., 12., 12., 12., 11.,\n",
      "        11., 11., 11., 11., 10., 10., 10., 10.,  9.,  9.,  9.,  9.,  9.,  8.,\n",
      "         8.,  8.,  8.,  8.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  6.,  6.,  6.,\n",
      "         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  5.,  5.,  5.,\n",
      "         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
      "         5.,  5.,  5.,  5.,  5.,  5.,  5.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Quantized test:\",  quantized_state_dict[\"slayer.srmKernel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1483)\n"
     ]
    }
   ],
   "source": [
    "print(global_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(global_zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'theta': tensor(72.), 'tauSr': tensor(72.), 'tauRef': tensor(12.), 'scaleRef': tensor(18.), 'tauRho': tensor(12.), 'scaleRho': tensor(12.)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def quantize_neuron_params(x):\n",
    "\n",
    "    dt_info = torch.iinfo(torch.int8)  # Use INT8 range\n",
    "    qmin, qmax = dt_info.min, dt_info.max\n",
    "\n",
    "    # Apply quantization (rounding to nearest discrete level) but store as float32\n",
    "    quantized = torch.clamp(((x / global_scale).round() + global_zero_point), qmin, qmax)\n",
    "\n",
    "    return quantized\n",
    "\n",
    "\n",
    "neuron_param_dict = { 'theta':    10, 'tauSr':    10.0, 'tauRef':   1.0,'scaleRef': 2 , 'tauRho':   1  ,'scaleRho': 1 }\n",
    "\n",
    "quantized_neuron_dict ={}\n",
    "\n",
    "for name,value in neuron_param_dict.items():\n",
    "    quantized_neuron_dict[name]=  quantize_neuron_params(value)\n",
    "\n",
    "print(quantized_neuron_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
